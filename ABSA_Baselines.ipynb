{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries and load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import warnings\n",
    "import spacy\n",
    "from os.path import join\n",
    "\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "path_train = \"data/semeval_16/ABSA16_Laptops_Train_English_SB2.xml\"\n",
    "path_test = \"data/semeval_16/EN_LAPT_SB2_TESTB.xml\"\n",
    "\n",
    "#For stanford POS Tagger\n",
    "home = \"stanford-postagger-full-2018-10-16\"\n",
    "from nltk.tag.stanford import StanfordPOSTagger as POS_Tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "_path_to_model = home + \"/models/english-bidirectional-distsim.tagger\"\n",
    "_path_to_jar = home + \"/stanford-postagger.jar\"\n",
    "stanford_tag = POS_Tag(model_filename=_path_to_model, path_to_jar=_path_to_jar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml parser\n",
    "def get_list(path):\n",
    "    tree=ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    text_list = []\n",
    "    opinion_list = []\n",
    "    for review in root.findall('Review'):\n",
    "        text_string=\"\"\n",
    "        opinion_inner_list=[]\n",
    "        for sent in review.findall('./sentences/sentence'):\n",
    "            text_string= text_string+ \" \"+ sent.find('text').text\n",
    "        text_list.append(text_string)\n",
    "        for opinion in review.findall('./Opinions/Opinion'):\n",
    "            opinion_dict = {\n",
    "                opinion.get('category').replace('#','_'): opinion.get('polarity')\n",
    "            }\n",
    "            opinion_inner_list.append(opinion_dict)\n",
    "        opinion_list.append(opinion_inner_list)\n",
    "    return text_list,opinion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only 20 most common aspect.\n",
    "def get_most_common_aspect(opinion_list):\n",
    "    import nltk\n",
    "    opinion= []\n",
    "    for inner_list in opinion_list:\n",
    "        for _dict in inner_list:\n",
    "            for key in _dict:\n",
    "                opinion.append(key)\n",
    "    most_common_aspect = [k for k,v in nltk.FreqDist(opinion).most_common(20)]\n",
    "    return most_common_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data frame\n",
    "def get_data_frame(text_list,opinion_list,most_common_aspect):\n",
    "    data={'Review':text_list}\n",
    "    df = pd.DataFrame(data)\n",
    "    if opinion_list:\n",
    "        for inner_list in opinion_list:\n",
    "            for _dict in inner_list:\n",
    "                for key in _dict:\n",
    "                    if key in most_common_aspect:\n",
    "                        df.loc[opinion_list.index(inner_list),key]=_dict[key]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data frame for aspect extraction task\n",
    "def get_aspect_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive','negative','neutral','conflict'],[1,1,1,1])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive'],[1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative','neutral','conflict'],[0,0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative'],[1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive','neutral','conflict'],[0,0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neutral_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['neutral','conflict'],[1,1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative','positive'],[0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To tag using stanford pos tagger\n",
    "def posTag(review):\n",
    "    tagged_text_list=[]\n",
    "    for text in review:\n",
    "        tagged_text_list.append(stanford_tag.tag(word_tokenize(text)))\n",
    "    return tagged_text_list\n",
    "#posTag(\"this is random text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the word with tag- noun,adjective,verb,adverb\n",
    "def filterTag(tagged_review):\n",
    "    final_text_list=[]\n",
    "    for text_list in tagged_review:\n",
    "        final_text=[]\n",
    "        for word,tag in text_list:\n",
    "            if tag in ['NN','NNS','NNP','NNPS','RB','RBR','RBS','JJ','JJR','JJS','VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                final_text.append(word)\n",
    "        final_text_list.append(' '.join(final_text))\n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_aspect(y,most_common_aspect):\n",
    "    position=[]\n",
    "    for innerlist in y:\n",
    "        position.append([i for i, j in enumerate(innerlist) if j == 1])\n",
    "    sorted_common=sorted(most_common_aspect)\n",
    "    dict_aspect=[]\n",
    "    for innerlist in position:\n",
    "        inner_dict={}\n",
    "        for word in sorted_common:\n",
    "            if sorted_common.index(word) in innerlist:\n",
    "                inner_dict[word]= 5\n",
    "            else:\n",
    "                inner_dict[word]=0\n",
    "        dict_aspect.append(inner_dict)\n",
    "    return dict_aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 : Opinion prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 PosTag train and test files and serialize them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1:\n",
    "#Making list to train\n",
    "train_text_list,train_opinion_list = get_list(path_train)\n",
    "most_common_aspect = get_most_common_aspect(train_opinion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This takes time to tag. Already tagged and saved. So, loading file ...\n",
    "#tagged_text_list_train=posTag(train_text_list)\n",
    "#joblib.dump(tagged_text_list_train, 'tagged_text_list_train.pkl')\n",
    "tagged_text_list_train=joblib.load('d/tagged_text_list_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train list after filter\n",
    "final_train_text_list=filterTag(tagged_text_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#get data frame\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_train_aspect = get_aspect_data_frame(df_train,most_common_aspect)\n",
    "df_train_aspect = df_train_aspect.reindex_axis(sorted(df_train_aspect.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar for test list\n",
    "test_text_list,test_opinion_list = get_list(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagged_text_list_test=posTag(test_text_list)\n",
    "#joblib.dump(tagged_text_list_test, 'tagged_text_list_test.pkl')\n",
    "tagged_text_list_test=joblib.load('d/tagged_text_list_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagged_text_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_text_list=filterTag(tagged_text_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "df_test_aspect = get_aspect_data_frame(df_test,most_common_aspect)\n",
    "df_test_aspect = df_test_aspect.reindex_axis(sorted(df_test_aspect.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_aspect.replace('',1, inplace=True)\n",
    "#df_test_aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Get necessary dataframes and mumpy arrays for text and labels respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the data frame according to aspect's name and separate data(X) and target(y)\n",
    "#df_train_aspect = df_train_aspect.sample(frac=1).reset_index(drop=True) #For randoming\n",
    "X_train= df_train_aspect.Review\n",
    "y_train = df_train_aspect.drop('Review',1)\n",
    "\n",
    "#df_test_aspect = df_test_aspect.sample(frac=1).reset_index(drop=True) #For randoming\n",
    "X_test = df_test_aspect.Review\n",
    "y_test = df_test_aspect.drop('Review',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change y_train to numpy array\n",
    "import numpy as np\n",
    "y_train = np.asarray(y_train, dtype=np.int64)\n",
    "y_test = np.asarray(y_test, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Generate word embeddings with sklearn's countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate word vecotors using CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "vect = CountVectorizer(max_df=1.0,stop_words='english')  \n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training - I. Naive Bayes', II. SVC, III. Linear SVC, IV. SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_aspect_dtm\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create various models. These are multi-label models.\n",
    "nb_classif = OneVsRestClassifier(MultinomialNB()).fit(X_train_dtm, y_train)\n",
    "C = 1.0 #SVregularization parameter\n",
    "svc = OneVsRestClassifier(svm.SVC(kernel='linear', C=C)).fit(X_train_dtm, y_train)\n",
    "lin_svc = OneVsRestClassifier(svm.LinearSVC(C=C)).fit(X_train_dtm, y_train)\n",
    "sgd = OneVsRestClassifier(SGDClassifier()).fit(X_train_dtm,y_train)\n",
    "#xg_model = xgb.XGBClassifier().fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the test data using classifiers\n",
    "y_pred_class = nb_classif.predict(X_test_dtm)\n",
    "y_pred_class_svc = svc.predict(X_test_dtm)\n",
    "y_pred_class_lin_svc = lin_svc.predict(X_test_dtm)\n",
    "y_pred_class_sgd = sgd.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following code to test metrics of all aspect extraction classifiers\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "0.05\n",
      "0.05\n",
      "0.0125\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred_class))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_svc))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_lin_svc))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.7112299465240641\n",
      "0.7321937321937322\n",
      "0.696875\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_sgd,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4576271186440678\n",
      "0.6440677966101694\n",
      "0.6222760290556901\n",
      "0.5399515738498789\n"
     ]
    }
   ],
   "source": [
    "print(metrics.recall_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_sgd,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5684210526315788\n",
      "0.6759847522236341\n",
      "0.6727748691099477\n",
      "0.6084583901773534\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_sgd,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.14      0.24        14\n",
      "           1       0.71      0.50      0.59        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.76      0.64      0.69        39\n",
      "           8       1.00      1.00      1.00        80\n",
      "           9       0.44      0.17      0.24        24\n",
      "          10       0.62      0.70      0.65        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.57      0.30      0.39        27\n",
      "          13       0.57      0.45      0.50        29\n",
      "          14       0.77      0.33      0.47        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.60      0.27      0.37        11\n",
      "\n",
      "   micro avg       0.75      0.46      0.57       413\n",
      "   macro avg       0.33      0.22      0.26       413\n",
      "weighted avg       0.57      0.46      0.49       413\n",
      " samples avg       0.78      0.50      0.57       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.68      0.71      0.69        24\n",
      "           2       0.86      0.50      0.63        12\n",
      "           3       0.12      0.25      0.17         4\n",
      "           4       0.56      0.43      0.49        21\n",
      "           5       0.75      0.38      0.50         8\n",
      "           6       0.20      0.14      0.17         7\n",
      "           7       0.74      0.67      0.70        39\n",
      "           8       1.00      0.97      0.99        80\n",
      "           9       0.63      0.50      0.56        24\n",
      "          10       0.68      0.74      0.71        46\n",
      "          11       0.33      0.40      0.36         5\n",
      "          12       0.83      0.74      0.78        27\n",
      "          13       0.56      0.66      0.60        29\n",
      "          14       0.60      0.40      0.48        30\n",
      "          15       0.67      0.50      0.57         4\n",
      "          16       0.18      0.22      0.20         9\n",
      "          17       0.80      0.27      0.40        15\n",
      "          18       1.00      0.25      0.40         4\n",
      "          19       0.60      0.27      0.37        11\n",
      "\n",
      "   micro avg       0.71      0.64      0.68       413\n",
      "   macro avg       0.63      0.50      0.53       413\n",
      "weighted avg       0.72      0.64      0.67       413\n",
      " samples avg       0.73      0.65      0.66       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.65      0.71      0.68        24\n",
      "           2       1.00      0.42      0.59        12\n",
      "           3       0.17      0.25      0.20         4\n",
      "           4       0.64      0.43      0.51        21\n",
      "           5       1.00      0.25      0.40         8\n",
      "           6       0.33      0.14      0.20         7\n",
      "           7       0.74      0.67      0.70        39\n",
      "           8       1.00      0.96      0.98        80\n",
      "           9       0.61      0.46      0.52        24\n",
      "          10       0.70      0.72      0.71        46\n",
      "          11       0.25      0.20      0.22         5\n",
      "          12       0.83      0.74      0.78        27\n",
      "          13       0.54      0.66      0.59        29\n",
      "          14       0.61      0.37      0.46        30\n",
      "          15       1.00      0.25      0.40         4\n",
      "          16       0.20      0.22      0.21         9\n",
      "          17       1.00      0.20      0.33        15\n",
      "          18       1.00      0.25      0.40         4\n",
      "          19       0.75      0.27      0.40        11\n",
      "\n",
      "   micro avg       0.73      0.62      0.67       413\n",
      "   macro avg       0.69      0.46      0.51       413\n",
      "weighted avg       0.75      0.62      0.66       413\n",
      " samples avg       0.74      0.63      0.65       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67        14\n",
      "           1       0.67      0.75      0.71        24\n",
      "           2       1.00      0.17      0.29        12\n",
      "           3       0.25      0.25      0.25         4\n",
      "           4       0.40      0.10      0.15        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.78      0.79      0.78        39\n",
      "           8       1.00      0.97      0.99        80\n",
      "           9       0.54      0.29      0.38        24\n",
      "          10       0.64      0.65      0.65        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.69      0.41      0.51        27\n",
      "          13       0.51      0.66      0.58        29\n",
      "          14       0.54      0.23      0.33        30\n",
      "          15       0.50      0.25      0.33         4\n",
      "          16       0.12      0.11      0.12         9\n",
      "          17       0.40      0.13      0.20        15\n",
      "          18       1.00      0.25      0.40         4\n",
      "          19       0.75      0.27      0.40        11\n",
      "\n",
      "   micro avg       0.70      0.54      0.61       413\n",
      "   macro avg       0.52      0.35      0.39       413\n",
      "weighted avg       0.66      0.54      0.57       413\n",
      " samples avg       0.74      0.59      0.61       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print(metrics.classification_report(y_test, y_pred_class))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_lin_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 : Aspect category prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 2:\n",
    "#Generating extra feature that indicates which aspect category is present in the review\n",
    "train_dict_aspect=get_dict_aspect(y_train, most_common_aspect)\n",
    "d_train=DictVectorizer() \n",
    "X_train_aspect_dtm = d_train.fit_transform(train_dict_aspect)\n",
    "\n",
    "#y_test is used to generated extra feature in order to test the performance of 2nd classifer.\n",
    "#Use y_pred_class_svc(Highest performer for aspect classification) as input for extra feature to test the overall performace.\n",
    "test_dict_aspect=get_dict_aspect(y_test,most_common_aspect)\n",
    "d_test=DictVectorizer() \n",
    "X_test_aspect_dtm = d_test.fit_transform(test_dict_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for classiflying positive,negative or neutral sentiment of all the aspects\n",
    "def classify_sentiment(df_train,df_test,X_train_aspect_dtm,X_test_aspect_dtm):\n",
    "    \n",
    "    df_train = df_train.reindex_axis(sorted(df_train_positive.columns), axis=1)\n",
    "    df_test = df_test.reindex_axis(sorted(df_test_positive.columns), axis=1)\n",
    "    \n",
    "    df_test.replace('',1, inplace=True)\n",
    "    #print(df_test.iloc[0])\n",
    "\n",
    "    import numpy as np\n",
    "    X_train = df_train.Review\n",
    "    y_train = df_train.drop('Review',1)\n",
    "    y_train = np.asarray(y_train, dtype=np.int64)\n",
    "\n",
    "    X_test = df_test.Review\n",
    "    y_test = df_test.drop('Review',1)\n",
    "    y_test = np.asarray(y_test, dtype=np.int64)\n",
    "\n",
    "    vect_sen = CountVectorizer(stop_words='english',ngram_range=(1,2))  \n",
    "    X_train_dtm = vect_sen.fit_transform(X_train)\n",
    "    X_test_dtm = vect_sen.transform(X_test)\n",
    "\n",
    "    #combining word vector with extra feature.\n",
    "    from scipy.sparse import hstack\n",
    "    X_train_dtm=hstack((X_train_dtm, X_train_aspect_dtm))\n",
    "    X_test_dtm=hstack((X_test_dtm, X_test_aspect_dtm))\n",
    "\n",
    "    C = 1.0 #SVregularization parameter\n",
    "    nb_classif = OneVsRestClassifier(MultinomialNB()).fit(X_train_dtm, y_train)\n",
    "    svc = OneVsRestClassifier(svm.SVC(kernel='linear', C=C)).fit(X_train_dtm, y_train)\n",
    "    lin_svc = OneVsRestClassifier(svm.LinearSVC(C=C)).fit(X_train_dtm, y_train)\n",
    "    sgd = OneVsRestClassifier(SGDClassifier()).fit(X_train_dtm,y_train)\n",
    "\n",
    "    y_pred_class= nb_classif.predict(X_test_dtm)\n",
    "    y_pred_class_svc = svc.predict(X_test_dtm)\n",
    "    y_pred_class_lin_svc = lin_svc.predict(X_test_dtm)\n",
    "    y_pred_class_sgd = sgd.predict(X_test_dtm)\n",
    "    return (y_test,y_pred_class,y_pred_class_svc,y_pred_class_lin_svc,y_pred_class_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrices(y_test,y_pred_class,y_pred_class_svc,y_pred_class_lin_svc,y_pred_class_sgd):\n",
    "    print(\"Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_svc))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_lin_svc))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_sgd))\n",
    "\n",
    "    print(\"\\nAverage precision:\")\n",
    "    print(metrics.precision_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "\n",
    "    print(\"\\nAverage recall:\")\n",
    "    print(metrics.recall_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "    \n",
    "    print(\"\\nAverage f1:\")\n",
    "    print(metrics.f1_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred_class))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_lin_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.025\n",
      "0.325\n",
      "0.3\n",
      "0.225\n",
      "\n",
      "Average precision:\n",
      "1.0\n",
      "0.976271186440678\n",
      "0.9959349593495935\n",
      "1.0\n",
      "\n",
      "Average recall:\n",
      "0.2033898305084746\n",
      "0.6973365617433414\n",
      "0.5932203389830508\n",
      "0.5835351089588378\n",
      "\n",
      "Average f1:\n",
      "0.33802816901408456\n",
      "0.8135593220338984\n",
      "0.7435508345978756\n",
      "0.7370030581039755\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00        39\n",
      "           8       1.00      0.88      0.93        80\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       1.00      0.30      0.47        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.00      0.00      0.00        27\n",
      "          13       0.00      0.00      0.00        29\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       1.00      0.20      0.34       413\n",
      "   macro avg       0.10      0.06      0.07       413\n",
      "weighted avg       0.31      0.20      0.23       413\n",
      " samples avg       0.88      0.24      0.36       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88        14\n",
      "           1       0.93      0.58      0.72        24\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       0.94      0.76      0.84        21\n",
      "           5       1.00      0.50      0.67         8\n",
      "           6       0.67      0.29      0.40         7\n",
      "           7       1.00      0.72      0.84        39\n",
      "           8       1.00      0.80      0.89        80\n",
      "           9       1.00      0.79      0.88        24\n",
      "          10       0.97      0.76      0.85        46\n",
      "          11       1.00      0.80      0.89         5\n",
      "          12       1.00      0.56      0.71        27\n",
      "          13       0.94      0.59      0.72        29\n",
      "          14       1.00      0.93      0.97        30\n",
      "          15       0.67      0.50      0.57         4\n",
      "          16       0.75      0.33      0.46         9\n",
      "          17       1.00      0.33      0.50        15\n",
      "          18       1.00      0.75      0.86         4\n",
      "          19       1.00      0.18      0.31        11\n",
      "\n",
      "   micro avg       0.98      0.70      0.81       413\n",
      "   macro avg       0.94      0.65      0.75       413\n",
      "weighted avg       0.97      0.70      0.80       413\n",
      " samples avg       0.87      0.68      0.74       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        14\n",
      "           1       0.93      0.54      0.68        24\n",
      "           2       1.00      0.42      0.59        12\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      0.62      0.76        21\n",
      "           5       1.00      0.12      0.22         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       1.00      0.64      0.78        39\n",
      "           8       1.00      0.80      0.89        80\n",
      "           9       1.00      0.75      0.86        24\n",
      "          10       1.00      0.76      0.86        46\n",
      "          11       1.00      0.40      0.57         5\n",
      "          12       1.00      0.41      0.58        27\n",
      "          13       1.00      0.52      0.68        29\n",
      "          14       1.00      0.70      0.82        30\n",
      "          15       1.00      0.25      0.40         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       1.00      0.27      0.42        15\n",
      "          18       1.00      0.75      0.86         4\n",
      "          19       1.00      0.09      0.17        11\n",
      "\n",
      "   micro avg       1.00      0.59      0.74       413\n",
      "   macro avg       0.90      0.48      0.60       413\n",
      "weighted avg       0.96      0.59      0.71       413\n",
      " samples avg       0.87      0.60      0.68       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        14\n",
      "           1       1.00      0.50      0.67        24\n",
      "           2       1.00      0.42      0.59        12\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      0.76      0.86        21\n",
      "           5       1.00      0.38      0.55         8\n",
      "           6       1.00      0.43      0.60         7\n",
      "           7       1.00      0.64      0.78        39\n",
      "           8       1.00      0.78      0.87        80\n",
      "           9       1.00      0.62      0.77        24\n",
      "          10       1.00      0.61      0.76        46\n",
      "          11       1.00      0.60      0.75         5\n",
      "          12       1.00      0.44      0.62        27\n",
      "          13       1.00      0.38      0.55        29\n",
      "          14       1.00      0.83      0.91        30\n",
      "          15       1.00      0.25      0.40         4\n",
      "          16       1.00      0.11      0.20         9\n",
      "          17       1.00      0.07      0.12        15\n",
      "          18       1.00      0.75      0.86         4\n",
      "          19       1.00      0.18      0.31        11\n",
      "\n",
      "   micro avg       1.00      0.58      0.74       413\n",
      "   macro avg       1.00      0.52      0.65       413\n",
      "weighted avg       1.00      0.58      0.71       413\n",
      " samples avg       0.86      0.57      0.66       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For positive sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_positive = get_positive_data_frame(df_train,most_common_aspect)\n",
    "df_test_positive = get_positive_data_frame(df_test,most_common_aspect)\n",
    "y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos=classify_sentiment(df_train_positive,df_test_positive,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.0\n",
      "0.075\n",
      "0.05\n",
      "0.0875\n",
      "\n",
      "Average precision:\n",
      "1.0\n",
      "0.9861111111111112\n",
      "1.0\n",
      "0.9824561403508771\n",
      "\n",
      "Average recall:\n",
      "0.024213075060532687\n",
      "0.17191283292978207\n",
      "0.13075060532687652\n",
      "0.13559322033898305\n",
      "\n",
      "Average f1:\n",
      "0.04728132387706856\n",
      "0.29278350515463913\n",
      "0.23126338329764454\n",
      "0.23829787234042552\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00        39\n",
      "           8       1.00      0.11      0.20        80\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       0.00      0.00      0.00        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.00      0.00      0.00        27\n",
      "          13       1.00      0.03      0.07        29\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       1.00      0.02      0.05       413\n",
      "   macro avg       0.10      0.01      0.01       413\n",
      "weighted avg       0.26      0.02      0.04       413\n",
      " samples avg       0.11      0.03      0.05       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25        14\n",
      "           1       1.00      0.38      0.55        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       1.00      0.10      0.17        21\n",
      "           5       1.00      0.38      0.55         8\n",
      "           6       1.00      0.29      0.44         7\n",
      "           7       1.00      0.03      0.05        39\n",
      "           8       1.00      0.16      0.28        80\n",
      "           9       1.00      0.08      0.15        24\n",
      "          10       1.00      0.20      0.33        46\n",
      "          11       1.00      0.20      0.33         5\n",
      "          12       0.75      0.11      0.19        27\n",
      "          13       1.00      0.34      0.51        29\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       1.00      0.67      0.80         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       1.00      0.73      0.84        11\n",
      "\n",
      "   micro avg       0.99      0.17      0.29       413\n",
      "   macro avg       0.69      0.19      0.27       413\n",
      "weighted avg       0.82      0.17      0.26       413\n",
      " samples avg       0.41      0.20      0.24       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13        14\n",
      "           1       1.00      0.25      0.40        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       1.00      0.14      0.25        21\n",
      "           5       1.00      0.25      0.40         8\n",
      "           6       1.00      0.14      0.25         7\n",
      "           7       0.00      0.00      0.00        39\n",
      "           8       1.00      0.16      0.28        80\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       1.00      0.15      0.26        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       1.00      0.04      0.07        27\n",
      "          13       1.00      0.34      0.51        29\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       1.00      0.44      0.62         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       1.00      0.55      0.71        11\n",
      "\n",
      "   micro avg       1.00      0.13      0.23       413\n",
      "   macro avg       0.55      0.13      0.19       413\n",
      "weighted avg       0.67      0.13      0.21       413\n",
      " samples avg       0.33      0.16      0.20       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13        14\n",
      "           1       1.00      0.29      0.45        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       1.00      0.10      0.17        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       1.00      0.43      0.60         7\n",
      "           7       1.00      0.03      0.05        39\n",
      "           8       1.00      0.20      0.33        80\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       1.00      0.20      0.33        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.00      0.00      0.00        27\n",
      "          13       1.00      0.24      0.39        29\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       1.00      0.33      0.50         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.88      0.64      0.74        11\n",
      "\n",
      "   micro avg       0.98      0.14      0.24       413\n",
      "   macro avg       0.49      0.13      0.18       413\n",
      "weighted avg       0.67      0.14      0.21       413\n",
      " samples avg       0.32      0.19      0.22       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For negative sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neg = get_negative_data_frame(df_train,most_common_aspect)\n",
    "df_test_neg = get_negative_data_frame(df_test,most_common_aspect)\n",
    "\n",
    "y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg=classify_sentiment(df_train_neg,df_test_neg,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Average precision:\n",
      "0.0\n",
      "0.9230769230769231\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Average recall:\n",
      "0.0\n",
      "0.029055690072639227\n",
      "0.007263922518159807\n",
      "0.007263922518159807\n",
      "\n",
      "Average f1:\n",
      "0.0\n",
      "0.05633802816901409\n",
      "0.014423076923076922\n",
      "0.014423076923076922\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00        39\n",
      "           8       0.00      0.00      0.00        80\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       0.00      0.00      0.00        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.00      0.00      0.00        27\n",
      "          13       0.00      0.00      0.00        29\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       413\n",
      "   macro avg       0.00      0.00      0.00       413\n",
      "weighted avg       0.00      0.00      0.00       413\n",
      " samples avg       0.00      0.00      0.00       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       1.00      0.18      0.30        39\n",
      "           8       0.00      0.00      0.00        80\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       1.00      0.04      0.08        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       1.00      0.04      0.07        27\n",
      "          13       0.00      0.00      0.00        29\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       1.00      0.13      0.24        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.92      0.03      0.06       413\n",
      "   macro avg       0.20      0.02      0.03       413\n",
      "weighted avg       0.31      0.03      0.05       413\n",
      " samples avg       0.11      0.02      0.03       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       1.00      0.08      0.14        39\n",
      "           8       0.00      0.00      0.00        80\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       0.00      0.00      0.00        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.00      0.00      0.00        27\n",
      "          13       0.00      0.00      0.00        29\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       1.00      0.01      0.01       413\n",
      "   macro avg       0.05      0.00      0.01       413\n",
      "weighted avg       0.09      0.01      0.01       413\n",
      " samples avg       0.04      0.01      0.01       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       1.00      0.05      0.10        39\n",
      "           8       0.00      0.00      0.00        80\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       0.00      0.00      0.00        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.00      0.00      0.00        27\n",
      "          13       0.00      0.00      0.00        29\n",
      "          14       1.00      0.03      0.06        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       1.00      0.01      0.01       413\n",
      "   macro avg       0.10      0.00      0.01       413\n",
      "weighted avg       0.17      0.01      0.01       413\n",
      " samples avg       0.04      0.01      0.01       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For neutral or conflict sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neu = get_neutral_data_frame(df_train,most_common_aspect)\n",
    "df_test_neu = get_neutral_data_frame(df_test,most_common_aspect)\n",
    "\n",
    "y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu=classify_sentiment(df_train_neu,df_test_neu,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full pipeline : ABSA of user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a laptop review:\n",
      "\n",
      "This is my first asus laptop. So far i am really enjoying this laptop. 512GB SSD is super fast. Battery life is also good and can last very long. I have no complain on screen quality too as display supports 4k videos. Maybe that is why it costs a lot. This is an expensive laptop and it's price is very high compared to other laptops of similar specs. So, if you have no trouble paying for this laptop, it is pretty good.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aspect Based Sentiment analyis of user's input.\n",
    "user_input=input(\"Enter a laptop review:\\n\\n\")\n",
    "#Enter a laptop review:\n",
    "\n",
    "#This is my first asus laptop. So far i am really enjoying this laptop. 512GB SSD is super fast. \n",
    "#Battery life is also good and can last very long. \n",
    "#I have no complain on screen quality too as display supports 4k videos. Maybe that is why it costs a lot. \n",
    "#This is an expensive laptop and it's price is very high compared to other laptops of similar specs. \n",
    "#So, if you have no trouble paying for this laptop, it is pretty good.\n",
    "\n",
    "#Preprocessing and vectorizing\n",
    "tagged_user_input = posTag([user_input])\n",
    "filter_tagged_user_input = filterTag(tagged_user_input)\n",
    "\n",
    "user_input_series=pd.Series(filter_tagged_user_input)\n",
    "user_input_series_dtm=vect.transform(user_input_series)\n",
    "\n",
    "predict_aspect= svc.predict(user_input_series_dtm)\n",
    "extra_feature=get_dict_aspect(predict_aspect, most_common_aspect)\n",
    "extra_feature_dtm=DictVectorizer().fit_transform(extra_feature)\n",
    "predict_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting weather the dectected aspect is positive or not\n",
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_positive = get_positive_data_frame(df_train,most_common_aspect)\n",
    "y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos=classify_sentiment(df_train_positive,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting weather the dectected aspect is negative or not\n",
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_negative = get_negative_data_frame(df_train,most_common_aspect)\n",
    "y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg=classify_sentiment(df_train_negative,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/nlp_vir/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting weather the dectected aspect is neutral or coflict or not\n",
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neutral = get_neutral_data_frame(df_train,most_common_aspect)\n",
    "y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu=classify_sentiment(df_train_neutral,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 8, 10, 13]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the aspect that is positive\n",
    "index_positive=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_pos.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_positive.append(i)\n",
    "index_positive         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the aspect that is negative\n",
    "index_negative=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_neg.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_negative.append(i)\n",
    "index_negative         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the aspect that is neutral\n",
    "index_neutral=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_neu.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_neutral.append(i)\n",
    "index_neutral         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_positive:\n",
    "    for index in index_positive:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_negative:\n",
    "    for index in index_negative:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_neutral:\n",
    "    for index in index_neutral:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": neutral or conflict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BATTERY_OPERATION_PERFORMANCE: positive',\n",
       " 'DISPLAY_GENERAL: positive',\n",
       " 'LAPTOP_GENERAL: positive',\n",
       " 'LAPTOP_OPERATION_PERFORMANCE: positive',\n",
       " 'LAPTOP_QUALITY: positive',\n",
       " 'LAPTOP_PRICE: neutral or conflict']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction of Aspect Based Sentiment Analaysis for user's input\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
